{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2df26a-9be4-48dd-af3f-809e2e8404e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gretel_client import Gretel, configure_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9623da6-0987-4627-a410-997156ed2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DOMAINS = 10\n",
    "NUM_SEEDS = 250\n",
    "NUM_PROMPTS_PER_SEED = 5\n",
    "GRETEL_API_KEY = \"TOKEN HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d338a43-0664-4f79-9b8d-708e9223a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai/auto\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06, 1.61 records/s]\n"
     ]
    }
   ],
   "source": [
    "# Domain prompt\n",
    "DOMAIN_PROMPT = f\"\"\"\n",
    "You are a data expert across all of the major industries/verticals. Generate a diverse dataset\n",
    "of domains and detailed descriptions of data seen in these domains.\n",
    "\n",
    "For example:\n",
    "\"healthcare\": \"Comprehensive data on patient demographics, medical histories, treatment protocols, and outcomes; drug efficacy studies and side effects.\",\n",
    "\"education\": \"Detailed records on student demographics, academic performance, curriculum efficacy, school management, and educational resource allocation.\",\n",
    "\"retail\": \"Extensive data on product sales, customer demographics, inventory levels, supplier information, and consumer buying patterns and preferences.\",\n",
    "\"finance\": \"Detailed financial data including stock market trends, transaction records, investment portfolios, risk assessment models, and banking operations.\",\n",
    "\"real estate\": \"Real estate market data covering property listings, pricing trends, property features, regional market analysis, and real estate investment returns.\"\n",
    "\n",
    "##### GUIDELINES\n",
    "The dataset should contain only four columns\n",
    "Column 1: domain\n",
    "Column 2: domain_description\n",
    "\"\"\"\n",
    "\n",
    "# Generate domain descriptions\n",
    "try:\n",
    "    gretel = Gretel(api_key=GRETEL_API_KEY)\n",
    "    tabl1m = gretel.factories.initialize_navigator_api(\"tabular\", backend_model='gretelai/auto')\n",
    "    tabl1m.request_timeout_sec = 60\n",
    "\n",
    "    domain_descriptions_pd = tabl1m.generate(prompt=DOMAIN_PROMPT, num_records=NUM_DOMAINS, as_dataframe=True,\n",
    "                                             top_p=0.92, temperature=0.8, stream=False)\n",
    "    domain_descriptions = {k.replace('-', '_'): v for k, v in zip(domain_descriptions_pd['domain'], domain_descriptions_pd['domain_description'])}\n",
    "    domain_descriptions = dict(islice(domain_descriptions.items(), NUM_DOMAINS))\n",
    "except Exception as e:\n",
    "    print(f\"Error generating table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6a27a5-11c3-4778-abd8-21c832a4d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User proficiencies\n",
    "user_proficiencies = {\n",
    "    \"beginner\",\n",
    "    \"intermediate\",\n",
    "    \"advanced\",\n",
    "    \"expert\"\n",
    "}\n",
    "\n",
    "# SQL complexities\n",
    "sql_complexity = {\n",
    "    \"basic SQL with a simple select statement\",\n",
    "    \"only one join (specify inner, outer, cross)\",\n",
    "    \"two or more joins (specify inner, outer, cross)\",\n",
    "    \"subqueries, including correlated and nested subqueries\",\n",
    "    \"common table expressions\",\n",
    "    \"aggregation functions (COUNT, SUM, AVG, MIN, MAX, etc.), and HAVING clause\",\n",
    "    \"set operations such as UNION, INTERSECT, and EXCEPT\",\n",
    "    \"window functions (e.g., ROW_NUMBER, LEAD, LAG, RANK, NTILE, PERCENT_RANK, etc.) with partitioning and ordering\",\n",
    "    \"pivoting and unpivoting\"\n",
    "}\n",
    "\n",
    "# SQL tasks\n",
    "sql_task = {\n",
    "    \"data definition: creating, altering, or dropping tables and other database objects\",\n",
    "    \"data retrieval: basic data fetching queries\",\n",
    "    \"data manipulation: inserting, updating, or deleting records\",\n",
    "    \"analytics and reporting: generating reports, dashboards, and analytical insights\",\n",
    "    \"transactional processing: SQL transaction control statements (e.g., BEGIN, COMMIT, ROLLBACK)\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820596e7-7c93-4483-9fa2-c2bb58f25a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 250 contextual tag permutations\n",
      "           domain                                   data_description  \\\n",
      "0     real estate  Real estate market data covering property list...   \n",
      "1          retail  Extensive data on product sales, customer demo...   \n",
      "2  transportation  Extensive data on fleet management, logistics,...   \n",
      "3   manufacturing  Detailed records on production processes, inve...   \n",
      "4     agriculture  Detailed data on crop yields, farming practice...   \n",
      "\n",
      "     user_level                                     sql_complexity  \\\n",
      "0      advanced           basic SQL with a simple select statement   \n",
      "1  intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
      "2        expert  set operations such as UNION, INTERSECT, and E...   \n",
      "3        expert    two or more joins (specify inner, outer, cross)   \n",
      "4      beginner                           common table expressions   \n",
      "\n",
      "                                            sql_task  \n",
      "0  analytics and reporting: generating reports, d...  \n",
      "1  data manipulation: inserting, updating, or del...  \n",
      "2        data retrieval: basic data fetching queries  \n",
      "3  transactional processing: SQL transaction cont...  \n",
      "4  data manipulation: inserting, updating, or del...  \n"
     ]
    }
   ],
   "source": [
    "# Generate contextual tag data\n",
    "sampled_contextual_tag_data = [\n",
    "    (\n",
    "        domain,\n",
    "        domain_descriptions[domain],\n",
    "        random.choice(list(user_proficiencies)),\n",
    "        random.choice(list(sql_complexity)),\n",
    "        random.choice(list(sql_task))\n",
    "    )\n",
    "    for _ in range(NUM_SEEDS)\n",
    "    for domain in [random.choice(list(domain_descriptions.keys()))]\n",
    "]\n",
    "# Convert sampled data to a DataFrame\n",
    "contextual_tags = pd.DataFrame(\n",
    "    sampled_contextual_tag_data,\n",
    "    columns=[\"domain\", \"data_description\", \"user_level\", \"sql_complexity\", \"sql_task\"]\n",
    ")\n",
    "print(f'Created {len(contextual_tags)} contextual tag permutations')\n",
    "print(contextual_tags.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b000c1-4762-465d-85bb-9fb559ec77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text to SQL data\n",
    "def generate_text2sql_data(domain: str, data_description: str, user_level: str, sql_complexity: str, sql_task: str, verbose=False) -> str:\n",
    "    PROMPT = f\"\"\"\n",
    "    You are a data and SQL expert. Generate a diverse dataset using the following guidelines\n",
    "\n",
    "    ##### GUIDELINES\n",
    "    The dataset should contain only four columns\n",
    "    Column 1: natural language prompt\n",
    "        * Column name: prompt\n",
    "        * a well-formulated question or command in everyday English, representing a user query to a database\n",
    "        * prompt should require using {user_level} level of SQL and ideally {sql_complexity}\n",
    "        * prompt should be in the {domain} domain and pertain to {data_description}\n",
    "        * prompt should pertain to {sql_task} first and foremost\n",
    "    Column 2: tables and views that already exist in the database\n",
    "        * Column name: context\n",
    "        * this should be database context, NOT the SQL query representing a user's prompt\n",
    "        * include complete executable SQL table CREATE statements and/or view CREATE statements with capitalized keywords\n",
    "        * only table CREATE and CREATE + INSERT statements are allowed as database context. No ALTER/DROP/UPDATE\n",
    "        * provide up to five tables/views that are relevant to the user's natural language prompt\n",
    "        * provide only the SQL code for create statements, separated by a semicolon\n",
    "        * make sure there is no text preceding or following SQL code\n",
    "        * do not use newline characters or breakline tags in SQL code\n",
    "        * do not use ellipsis anywhere: this should be a valid, executable SQL statement\n",
    "        * do not use phrases like \"same as previous example\"\n",
    "        * table names and schemas should correspond to the {domain} domain and focus on {data_description}\n",
    "        * make sure there is no text of any kind preceding or following SQL code\n",
    "    Column 3: SQL query\n",
    "        * Column name: sql\n",
    "        * A complete and executable SQL query used to answer/execute the natural language prompt\n",
    "        * do not use ellipsis anywhere: this should be a valid, executable SQL statement\n",
    "        * SQL should be based on the database context generated above\n",
    "        * To the extent possible, SQL should leverage {sql_complexity}\n",
    "        * SQL should be written at an {user_level} SQL proficiency level\n",
    "        * do not use newline characters or breakline tags in SQL code\n",
    "        * make sure there is no text of any kind preceding or following SQL code\n",
    "    Column 4: explanation\n",
    "        * Column name: explanation\n",
    "        * a step-by-step explanation of what the SQL query is doing\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(PROMPT)\n",
    "\n",
    "    try:\n",
    "        gretel = Gretel(api_key=GRETEL_API_KEY)\n",
    "        tabl1m = gretel.factories.initialize_navigator_api(\"tabular\", backend_model='gretelai-google/gemini-pro')\n",
    "        tabl1m.request_timeout_sec = 60\n",
    "        prompt_context = tabl1m.generate(prompt=PROMPT, num_records=NUM_PROMPTS_PER_SEED, as_dataframe=True,\n",
    "                                         top_p=0.92, top_k=40, temperature=0.8, stream=False)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating table: {e}\"\n",
    "\n",
    "    # return the pandas dataframe as json so we can then expand in Pandas\n",
    "    return prompt_context.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e736b784-d301-4ae5-b420-c9fb3b27987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gretelai/auto', 'gretelai/Mistral-7B-Instruct-v0.2/industry', 'gretelai-azure/gpt-3.5-turbo', 'gretelai-google/gemini-pro']\n"
     ]
    }
   ],
   "source": [
    "print(gretel.factories.get_navigator_model_list(\"tabular\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efee2050-c5e3-4d60-ab2f-e6460c266891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Function to apply generate_text2sql_data and handle errors\n",
    "def safe_generate_text2sql_data_with_retry(row, max_retries=2):\n",
    "    retries = 0\n",
    "    wait_time = random.uniform(3, 10)\n",
    "    time.sleep(wait_time)\n",
    "    while retries <= max_retries:\n",
    "        try:\n",
    "            return generate_text2sql_data(row['domain'], row['data_description'], row['user_level'], row['sql_complexity'], row['sql_task'])\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")\n",
    "            if '403' in str(e) and retries < max_retries:\n",
    "                print(f\"403 ERROR! retry: {retries+1}/{max_retries}\")\n",
    "                retries += 1\n",
    "                wait_time = random.uniform(3, 10)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return f\"error generating: {e}\"\n",
    "\n",
    "# Parallelize the application of generate_text2sql_data\n",
    "def parallel_apply(df, func, num_workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = {executor.submit(func, row): idx for idx, row in df.iterrows()}\n",
    "        results = []\n",
    "        for future in as_completed(futures):\n",
    "            idx = futures[future]\n",
    "            try:\n",
    "                results.append(future.result())\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                results.append(f\"error generating: {e}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394fb3ef-b47d-4e1a-9f92-e7ab0e4d52a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:17,? records/s]s/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.11 records/s]\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:23, 0.04 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:26, 0.09 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:22, 0.10 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:28, 0.14 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29, 0.17 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26, 0.19 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:32, 0.17 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05, 0.43 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07, 0.43 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10, 0.48 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:04, 0.44 records/s][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05, 0.60 records/s][A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.10 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.21 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.05 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:36, 0.06 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.19 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:31, 0.06 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:17, 0.06 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:09, 0.38 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12, 0.36 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:48, 0.06 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:50, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:42, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17, 0.28 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:44, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:02, 0.08 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:41, 0.05 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:44, 0.08 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:14, 0.35 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:15, 0.06 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:02, 0.08 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.15 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.20 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:39, 0.03 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:22, 0.13 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:32, 0.11 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:46, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:45, 0.15 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:45, 0.11 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:46, 0.07 records/s]\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27, 0.08 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:09,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:50, 0.10 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:58, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:42, 0.11 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.16 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51, 0.10 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23, 0.21 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:41, 0.04 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:26,? records/s]s/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:44, 0.08 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.18 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.26 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15, 0.36 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:53, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.05 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25, 0.20 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.09 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.25 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:21, 0.05 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.18 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20, 0.25 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:51, 0.08 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:37, 0.09 records/s]\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:01, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:29, 0.08 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:56, 0.09 records/s][A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:19, 0.05 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.17 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.26 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:45, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.27 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.31 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:55, 0.08 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:57, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:45, 0.04 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31, 0.16 records/s]\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26, 0.15 records/s]\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:51, 0.07 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:54, 0.10 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31, 0.16 records/s][A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.14 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:09,? records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:07, 0.07 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:19, 0.05 records/s][A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:38, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:41, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:32, 0.06 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:41, 0.08 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:51, 0.06 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:37, 0.09 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:38, 0.14 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:40, 0.12 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.10 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17, 0.18 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:01, 0.05 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:02, 0.08 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25, 0.16 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:41, 0.09 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:43, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32, 0.15 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.11 records/s][A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.10 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11, 0.21 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12, 0.30 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:21, 0.05 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.30 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:26, 0.08 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:16, 0.06 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:25, 0.07 records/s][A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:31, 0.11 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:20, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:21, 0.19 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22, 0.26 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25, 0.20 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.17 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:53, 0.07 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:55, 0.09 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.21 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.34 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13, 0.36 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n",
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17, 0.29 records/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'An error has occurred. Tip: write your prompt clearly and remove parts that may be sensitive. Please try again or contact support for help.'. Retrying.\n",
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:18, 0.05 records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:56, 0.03 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:29, 0.04 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:07, 0.07 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:   0%|          | 0/5 [00:32,? records/s]s/s]\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.09 records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.11 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:56, 0.08 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:25, 0.12 records/s][A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'An error has occurred. Tip: write your prompt clearly and remove parts that may be sensitive. Please try again or contact support for help.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:08, 0.07 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:34, 0.12 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:46, 0.05 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.20 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.17 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49, 0.09 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49, 0.10 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.29 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15, 0.27 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20, 0.24 records/s]\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:40, 0.02 records/s]\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:20, 0.19 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22, 0.22 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:16, 0.12 records/s][A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.35 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:07,? records/s]s/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:24, 0.12 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11, 0.43 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:16, 0.06 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:34, 0.11 records/s][A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:25, 0.08 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.17 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.33 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:39, 0.13 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:40, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:10, 0.47 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:28, 0.12 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:29, 0.19 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12, 0.40 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12, 0.31 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.20 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:35, 0.14 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:15, 0.32 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.28 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.17 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.30 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.38 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:22, 0.04 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17, 0.31 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:03, 0.28 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05, 0.61 records/s][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:09, 0.44 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09, 0.52 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.31 records/s]\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:37, 0.14 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.29 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.28 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.38 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.28 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:16, 0.24 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49, 0.10 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27, 0.15 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28, 0.18 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.22 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.08 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.23 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17, 0.12 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:41, 0.04 records/s]\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:47, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:39, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:02, 0.08 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:39, 0.08 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:31, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:45, 0.10 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:54, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:20, 0.05 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:17, 0.06 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:31, 0.07 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:38, 0.09 records/s]\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:33, 0.06 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:18, 0.12 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:49, 0.09 records/s][A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:28, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:19,? records/s]s/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:54, 0.09 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:43, 0.09 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.22 records/s]\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.10 records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.09 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.22 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17, 0.35 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.28 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:18, 0.27 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.15 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30, 0.16 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17, 0.12 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:15, 0.07 records/s][A\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:14,? records/s]s/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10, 0.20 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:34, 0.08 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:15, 0.19 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:31, 0.06 records/s]\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.17 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.34 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.15 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.30 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:33, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:50, 0.09 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.19 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:04, 0.06 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:15, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:09, 0.36 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15, 0.13 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12, 0.36 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.26 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.23 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05, 0.45 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.08 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10, 0.49 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:39, 0.13 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:40, 0.12 records/s][A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.08 records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.05 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:16, 0.06 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07, 0.43 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:40, 0.07 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:36, 0.03 records/s][A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:49, 0.08 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:50, 0.12 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51, 0.10 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20, 0.24 records/s]\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.30 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.32 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13, 0.33 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:15, 0.31 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.16 records/s][A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:12, 0.08 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:14,? records/s]s/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17, 0.20 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:25, 0.11 records/s]\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:21, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:08,? records/s]s/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:31, 0.13 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36, 0.14 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.14 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.32 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10, 0.46 records/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:12, 0.08 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.15 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15, 0.15 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.16 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19, 0.18 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.22 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.18 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.32 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08, 0.45 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.06 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.37 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:33, 0.15 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.09 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31, 0.16 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.17 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36, 0.09 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:40, 0.12 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:15, 0.31 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17, 0.18 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49, 0.10 records/s]\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:18, 0.11 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07, 0.53 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:31, 0.15 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09, 0.55 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:08, 0.56 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10, 0.47 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s]\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:38, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.11 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25, 0.20 records/s][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25, 0.19 records/s][A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11, 0.19 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17, 0.18 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:22,? records/s]s/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.09 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'An error has occurred. Tip: write your prompt clearly and remove parts that may be sensitive. Please try again or contact support for help.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.05 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.12 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:49, 0.06 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:16, 0.31 records/s]\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:51, 0.04 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32, 0.15 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.11 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:10, 0.50 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.37 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32, 0.15 records/s]\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:07, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08, 0.40 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:10, 0.46 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:12, 0.08 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.22 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:20, 0.05 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:36, 0.04 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23, 0.17 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:40, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30, 0.16 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.08 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:25, 0.09 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:26, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:28, 0.22 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:23, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:26, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:27, 0.19 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31, 0.16 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:23, 0.09 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.18 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:31, 0.10 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17, 0.30 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22, 0.22 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:17, 0.06 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:46, 0.06 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:26, 0.04 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.23 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:54, 0.08 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.27 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18, 0.16 records/s]\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:07, 0.73 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:23, 0.10 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:11, 0.07 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:32, 0.10 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:33, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.15 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.20 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:41, 0.12 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.10 records/s]\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.24 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:24, 0.20 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17, 0.26 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27, 0.18 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:18, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.25 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.29 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.19 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:34, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31, 0.16 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:20, 0.10 records/s]\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:45, 0.11 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.20 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29, 0.20 records/s][A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29, 0.17 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.18 records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.30 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.28 records/s][A\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:07,? records/s]s/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15, 0.26 records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:19, 0.05 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:21, 0.11 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29, 0.17 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:25, 0.15 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27, 0.18 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:03, 0.27 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:04, 0.51 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05, 0.59 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:33, 0.15 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.16 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:20, 0.20 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.19 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17, 0.13 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.31 records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27, 0.07 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:28, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08, 0.40 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13, 0.30 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29, 0.10 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:40, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:43, 0.11 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:37, 0.11 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05, 0.41 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07, 0.41 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:09, 0.47 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:00, 0.08 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.08 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:21, 0.10 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:04, 0.08 records/s][A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:28, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.11 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11, 0.19 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12, 0.29 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:20, 0.10 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:22, 0.17 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:39, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.10 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:43, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.24 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.17 records/s]\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17, 0.19 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36, 0.14 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.17 records/s][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:21, 0.05 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:16, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:25, 0.08 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.08 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:12, 0.08 records/s][A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:42, 0.07 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'An error has occurred. Tip: write your prompt clearly and remove parts that may be sensitive. Please try again or contact support for help.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:52, 0.02 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:00, 0.05 records/s][A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:28, 0.03 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:31, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.11 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11, 0.20 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:03, 0.25 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.20 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:38, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.25 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12, 0.39 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:01, 0.04 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:03, 0.07 records/s]\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:30, 0.12 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:11, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13, 0.24 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:14, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:53, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.15 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28, 0.17 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:18, 0.05 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.23 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:25, 0.09 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.10 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.30 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:34, 0.05 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.23 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:51, 0.05 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15, 0.28 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:58, 0.07 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:58, 0.09 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22, 0.23 records/s]\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:43, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:50, 0.10 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:50, 0.08 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:54, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.19 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.28 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:09, 0.37 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:11, 0.41 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:22, 0.04 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20, 0.20 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.23 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:28, 0.08 records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27, 0.08 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:31, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.23 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:34, 0.17 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37, 0.13 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:35, 0.15 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.22 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:39, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.30 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07, 0.45 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.17 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.30 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12, 0.45 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12, 0.39 records/s][A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.27 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.30 records/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:17, 0.06 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.12 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20, 0.21 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:20, 0.31 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.22 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:12, 0.08 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:28, 0.08 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:30, 0.13 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:33, 0.17 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.14 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:28, 0.07 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.08 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.17 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:45, 0.10 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:45, 0.11 records/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:16, 0.35 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:42, 0.07 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:51, 0.10 records/s][A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:22, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:28, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17, 0.12 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20, 0.17 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:33, 0.16 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19, 0.10 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.11 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28, 0.18 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17, 0.28 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:32, 0.15 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48, 0.10 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:24, 0.20 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.15 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.24 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.30 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.18 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:10, 0.10 records/s]\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:16, 0.26 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:09, 0.34 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.27 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:14, 0.35 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:14, 0.36 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.38 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.29 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:22, 0.14 records/s][A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.10 records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.23 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:09, 0.37 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13, 0.32 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.14 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18, 0.28 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:42, 0.08 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48, 0.10 records/s][A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:28, 0.10 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.15 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.27 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12, 0.27 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:29, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:07,? records/s]s/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15, 0.27 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20, 0.24 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:54, 0.09 records/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20, 0.16 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:57, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:13,? records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10, 0.20 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:35, 0.13 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36, 0.14 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.11 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17, 0.25 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.28 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12, 0.38 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23, 0.21 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:24, 0.21 records/s]\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19, 0.17 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.18 records/s]\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:24, 0.18 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.27 records/s][A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:14, 0.32 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.27 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.15 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:15, 0.07 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.25 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12, 0.38 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19, 0.26 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:31, 0.09 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:33, 0.14 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:19, 0.05 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.18 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:41, 0.10 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:25, 0.15 records/s]\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:19, 0.24 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.24 records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.15 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.11 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.22 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:38, 0.03 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:23, 0.04 records/s]\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:18, 0.28 records/s]\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15, 0.28 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30, 0.16 records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.20 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'An error has occurred. Tip: write your prompt clearly and remove parts that may be sensitive. Please try again or contact support for help.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:43, 0.11 records/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:13, 0.07 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.21 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:19, 0.03 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.34 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08, 0.43 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:08, 0.60 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:23, 0.04 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:23, 0.04 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10, 0.47 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.08 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:10,? records/s]s/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:43, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:16, 0.12 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:08, 0.12 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:31, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:45, 0.04 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:49, 0.07 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:42, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:55, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:23, 0.12 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:30, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:58, 0.08 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:58, 0.09 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.34 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:12, 0.41 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:41, 0.11 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:41, 0.12 records/s]\n",
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:15, 0.32 records/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:29, 0.07 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:39, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:23, 0.04 records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:16, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.17 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:14, 0.25 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:29, 0.08 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23, 0.17 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.14 records/s]\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:39, 0.13 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:41, 0.12 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12, 0.28 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37, 0.13 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:16, 0.26 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:27, 0.15 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.28 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.11 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.31 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:11, 0.39 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.14 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.36 records/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:27, 0.04 records/s][A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:40, 0.14 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'An error has occurred. Tip: write your prompt clearly and remove parts that may be sensitive. Please try again or contact support for help.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:22,? records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:56, 0.09 records/s][A\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:35,? records/s]\n",
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:55, 0.06 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09, 0.23 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11, 0.29 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.31 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:14, 0.07 records/s][A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:16, 0.07 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:25, 0.22 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:08,? records/s]s/s][A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:35, 0.14 records/s]\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.08 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14, 0.16 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:27, 0.04 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17, 0.20 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:19, 0.26 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.23 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:06, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07, 0.51 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:19, 0.05 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:21, 0.16 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22, 0.22 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27, 0.08 records/s]\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:52, 0.06 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:34, 0.14 records/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.13 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10, 0.22 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:24, 0.04 records/s]\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13, 0.24 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:14, 0.35 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:30, 0.07 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:12, 0.06 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23, 0.22 records/s]\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:09, 0.10 records/s]\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13, 0.37 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:23, 0.07 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:24, 0.06 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:15, 0.33 records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48, 0.10 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.20 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06, 0.33 records/s]\u001b[A\n",
      "Generating records:   0%|          | 0/5 [00:07,? records/s]s/s]\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:11, 0.38 records/s]\u001b[A\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:19, 0.05 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:14, 0.34 records/s]\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:24, 0.09 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:30, 0.12 records/s]\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:31, 0.06 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:12,? records/s]s/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received error during generation: 'Unfortunately the AI system could not return data. Please make sure that your request is valid and relevant for tabular data, and does not include sensitive topics. Clearly writing out your request with examples or bulleted list of columns can help. Please try again or contact support.'. Retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:48, 0.06 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:55, 0.07 records/s]\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:07, 0.14 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:02, 0.08 records/s]\u001b[A\u001b[A\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:42, 0.05 records/s]\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:13, 0.15 records/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:11, 0.09 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15, 0.15 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:23, 0.06 records/s]\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19, 0.18 records/s]\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36, 0.07 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16, 0.18 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17, 0.29 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23, 0.20 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28, 0.17 records/s][A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.17 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:05, 0.19 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48, 0.10 records/s]\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08, 0.26 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07, 0.29 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10, 0.32 records/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08, 0.39 records/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]\n",
      "\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:11, 0.41 records/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13, 0.33 records/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  20%|â–ˆâ–ˆ        | 1/5 [00:04, 0.20 records/s]\n",
      "\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17, 0.28 records/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:08, 0.39 records/s]\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21, 0.23 records/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:11, 0.36 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.36 records/s]\u001b[A\n",
      "\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13, 0.36 records/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records:   0%|          | 0/5 [00:00,? records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend model: gretelai-google/gemini-pro\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ðŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:11, 0.40 records/s]\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12, 0.40 records/s]\u001b[A\n",
      "\n",
      "Generating records:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12, 0.18 records/s]\u001b[A\n",
      "Generating records:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13, 0.31 records/s]\u001b[A\n",
      "Generating records:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:14, 0.39 records/s]\u001b[A\n",
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:16, 0.30 records/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "test = contextual_tags\n",
    "test['text2sql_json'] = parallel_apply(test, safe_generate_text2sql_data_with_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ef93a3-0157-4bbf-9a19-f40ab893c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 records remain after removing errors\n"
     ]
    }
   ],
   "source": [
    "test_errors = test[test['text2sql_json'].str.contains('Error generating')]\n",
    "test2 = test[~test['text2sql_json'].str.contains('Error generating')]\n",
    "print(f'{len(test2)} records remain after removing errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9aaf2ea-2d88-48ec-9d39-86fd197f8779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>data_description</th>\n",
       "      <th>user_level</th>\n",
       "      <th>sql_complexity</th>\n",
       "      <th>sql_task</th>\n",
       "      <th>text2sql_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real estate</td>\n",
       "      <td>Real estate market data covering property list...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>basic SQL with a simple select statement</td>\n",
       "      <td>analytics and reporting: generating reports, d...</td>\n",
       "      <td>Error generating table: (403)\\nReason: Forbidd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retail</td>\n",
       "      <td>Extensive data on product sales, customer demo...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>aggregation functions (COUNT, SUM, AVG, MIN, M...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Identify the top five cities i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>expert</td>\n",
       "      <td>set operations such as UNION, INTERSECT, and E...</td>\n",
       "      <td>data retrieval: basic data fetching queries</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Which customers have placed or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manufacturing</td>\n",
       "      <td>Detailed records on production processes, inve...</td>\n",
       "      <td>expert</td>\n",
       "      <td>two or more joins (specify inner, outer, cross)</td>\n",
       "      <td>transactional processing: SQL transaction cont...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Find all orders placed in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>Detailed data on crop yields, farming practice...</td>\n",
       "      <td>beginner</td>\n",
       "      <td>common table expressions</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Which countries have the highe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>manufacturing</td>\n",
       "      <td>Detailed records on production processes, inve...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>set operations such as UNION, INTERSECT, and E...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Which states have the highest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>Detailed data on crop yields, farming practice...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>only one join (specify inner, outer, cross)</td>\n",
       "      <td>transactional processing: SQL transaction cont...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"What is the average yield of w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>technology</td>\n",
       "      <td>Comprehensive data on product development, mar...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>pivoting and unpivoting</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Which products are currently i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>manufacturing</td>\n",
       "      <td>Detailed records on production processes, inve...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>subqueries, including correlated and nested su...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"How many different products di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>window functions (e.g., ROW_NUMBER, LEAD, LAG,...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>{\"prompt\":{\"0\":\"Add a new record to the Vehicl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain                                   data_description  \\\n",
       "0       real estate  Real estate market data covering property list...   \n",
       "1            retail  Extensive data on product sales, customer demo...   \n",
       "2    transportation  Extensive data on fleet management, logistics,...   \n",
       "3     manufacturing  Detailed records on production processes, inve...   \n",
       "4       agriculture  Detailed data on crop yields, farming practice...   \n",
       "..              ...                                                ...   \n",
       "245   manufacturing  Detailed records on production processes, inve...   \n",
       "246     agriculture  Detailed data on crop yields, farming practice...   \n",
       "247      technology  Comprehensive data on product development, mar...   \n",
       "248   manufacturing  Detailed records on production processes, inve...   \n",
       "249  transportation  Extensive data on fleet management, logistics,...   \n",
       "\n",
       "       user_level                                     sql_complexity  \\\n",
       "0        advanced           basic SQL with a simple select statement   \n",
       "1    intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
       "2          expert  set operations such as UNION, INTERSECT, and E...   \n",
       "3          expert    two or more joins (specify inner, outer, cross)   \n",
       "4        beginner                           common table expressions   \n",
       "..            ...                                                ...   \n",
       "245  intermediate  set operations such as UNION, INTERSECT, and E...   \n",
       "246  intermediate        only one join (specify inner, outer, cross)   \n",
       "247  intermediate                            pivoting and unpivoting   \n",
       "248      advanced  subqueries, including correlated and nested su...   \n",
       "249  intermediate  window functions (e.g., ROW_NUMBER, LEAD, LAG,...   \n",
       "\n",
       "                                              sql_task  \\\n",
       "0    analytics and reporting: generating reports, d...   \n",
       "1    data manipulation: inserting, updating, or del...   \n",
       "2          data retrieval: basic data fetching queries   \n",
       "3    transactional processing: SQL transaction cont...   \n",
       "4    data manipulation: inserting, updating, or del...   \n",
       "..                                                 ...   \n",
       "245  data manipulation: inserting, updating, or del...   \n",
       "246  transactional processing: SQL transaction cont...   \n",
       "247  data manipulation: inserting, updating, or del...   \n",
       "248  data manipulation: inserting, updating, or del...   \n",
       "249  data manipulation: inserting, updating, or del...   \n",
       "\n",
       "                                         text2sql_json  \n",
       "0    Error generating table: (403)\\nReason: Forbidd...  \n",
       "1    {\"prompt\":{\"0\":\"Identify the top five cities i...  \n",
       "2    {\"prompt\":{\"0\":\"Which customers have placed or...  \n",
       "3    {\"prompt\":{\"0\":\"Find all orders placed in the ...  \n",
       "4    {\"prompt\":{\"0\":\"Which countries have the highe...  \n",
       "..                                                 ...  \n",
       "245  {\"prompt\":{\"0\":\"Which states have the highest ...  \n",
       "246  {\"prompt\":{\"0\":\"What is the average yield of w...  \n",
       "247  {\"prompt\":{\"0\":\"Which products are currently i...  \n",
       "248  {\"prompt\":{\"0\":\"How many different products di...  \n",
       "249  {\"prompt\":{\"0\":\"Add a new record to the Vehicl...  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44d49c88-4350-4cd1-886f-b840e54a981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5395/3429042814.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2['parsed_json'] = test2.apply(parse_json, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Parse JSON\n",
    "def parse_json(row):\n",
    "    try:\n",
    "        return json.loads(row['text2sql_json'])\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "test2['parsed_json'] = test2.apply(parse_json, axis=1)\n",
    "\n",
    "# Transform maps into arrays of keys and values, zip and explode\n",
    "def explode_json(row):\n",
    "    data = []\n",
    "    for key in row['parsed_json']['prompt'].keys():\n",
    "        data.append({\n",
    "            \"domain\": row['domain'],\n",
    "            \"data_description\": row['data_description'],\n",
    "            \"user_level\": row['user_level'],\n",
    "            \"sql_complexity\": row['sql_complexity'],\n",
    "            \"sql_task\": row['sql_task'],\n",
    "            \"prompt\": row['parsed_json']['prompt'][key],\n",
    "            \"context\": row['parsed_json']['context'][key],\n",
    "            \"sql\": row['parsed_json']['sql'][key],\n",
    "            \"explanation\": row['parsed_json']['explanation'][key]\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "exploded_text2sql_data = pd.concat([explode_json(row) for idx, row in test2.iterrows()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f150816-5718-4574-93e4-fce0058e7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_text2sql_data.iloc[:1000].to_csv(\"navigator_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f277af0-1eef-4a82-aa8b-ed6ee1e244d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>data_description</th>\n",
       "      <th>user_level</th>\n",
       "      <th>sql_complexity</th>\n",
       "      <th>sql_task</th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>sql</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retail</td>\n",
       "      <td>Extensive data on product sales, customer demo...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>aggregation functions (COUNT, SUM, AVG, MIN, M...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Identify the top five cities in the United Sta...</td>\n",
       "      <td>CREATE TABLE listings (\\nlisting_id INT PRIMAR...</td>\n",
       "      <td>SELECT city, state, median_price FROM median_p...</td>\n",
       "      <td>This query first creates a view called `median...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retail</td>\n",
       "      <td>Extensive data on product sales, customer demo...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>aggregation functions (COUNT, SUM, AVG, MIN, M...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>What is the average price per square foot for ...</td>\n",
       "      <td>CREATE TABLE listings (\\nlisting_id INT PRIMAR...</td>\n",
       "      <td>SELECT AVG(price / square_footage) AS average_...</td>\n",
       "      <td>This query calculates the average price per sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retail</td>\n",
       "      <td>Extensive data on product sales, customer demo...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>aggregation functions (COUNT, SUM, AVG, MIN, M...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>What are the top 5 cities in the United States...</td>\n",
       "      <td>CREATE TABLE US_Cities_Median_Home_Prices (Cit...</td>\n",
       "      <td>SELECT City, State, Median_Home_Price FROM US_...</td>\n",
       "      <td>This SQL query selects the City, State, and Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retail</td>\n",
       "      <td>Extensive data on product sales, customer demo...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>aggregation functions (COUNT, SUM, AVG, MIN, M...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Show me the average price per square foot for ...</td>\n",
       "      <td>CREATE TABLE US_States_Avg_Price_Per_SqFt (Sta...</td>\n",
       "      <td>SELECT State, Avg_Price_Per_SqFt FROM US_State...</td>\n",
       "      <td>This SQL query selects the State and Avg_Price...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retail</td>\n",
       "      <td>Extensive data on product sales, customer demo...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>aggregation functions (COUNT, SUM, AVG, MIN, M...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Find all properties in California that have a ...</td>\n",
       "      <td>CREATE TABLE CA_Properties (Property_ID INT, A...</td>\n",
       "      <td>SELECT Address, List_Price, Bedrooms FROM CA_P...</td>\n",
       "      <td>This SQL query selects the Address, List_Price...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>window functions (e.g., ROW_NUMBER, LEAD, LAG,...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Add a new record to the Vehicles table for a N...</td>\n",
       "      <td>CREATE TABLE Vehicles (vehicle_id INT PRIMARY ...</td>\n",
       "      <td>INSERT INTO Vehicles (make, model, license_pla...</td>\n",
       "      <td>This SQL statement inserts a new row into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>window functions (e.g., ROW_NUMBER, LEAD, LAG,...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Update the customer's address in the Customers...</td>\n",
       "      <td>CREATE TABLE Customers (customer_id INT PRIMAR...</td>\n",
       "      <td>UPDATE Customers SET address = '123 Main St, A...</td>\n",
       "      <td>This SQL statement updates the address of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>window functions (e.g., ROW_NUMBER, LEAD, LAG,...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Delete the record from the Orders table where ...</td>\n",
       "      <td>CREATE TABLE Orders (order_id INT PRIMARY KEY,...</td>\n",
       "      <td>DELETE FROM Orders WHERE order_id = 789;</td>\n",
       "      <td>This SQL statement deletes the row from the Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>window functions (e.g., ROW_NUMBER, LEAD, LAG,...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Calculate the average mileage of all vehicles ...</td>\n",
       "      <td>CREATE TABLE Vehicles (vehicle_id INT PRIMARY ...</td>\n",
       "      <td>SELECT make, AVG(mileage) AS average_mileage F...</td>\n",
       "      <td>This SQL statement calculates the average mile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>transportation</td>\n",
       "      <td>Extensive data on fleet management, logistics,...</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>window functions (e.g., ROW_NUMBER, LEAD, LAG,...</td>\n",
       "      <td>data manipulation: inserting, updating, or del...</td>\n",
       "      <td>Find the top 5 customers with the highest tota...</td>\n",
       "      <td>CREATE TABLE Orders (order_id INT PRIMARY KEY,...</td>\n",
       "      <td>SELECT c.name, SUM(o.total_amount) AS total_or...</td>\n",
       "      <td>This SQL statement finds the top 5 customers w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>975 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain                                   data_description  \\\n",
       "0            retail  Extensive data on product sales, customer demo...   \n",
       "1            retail  Extensive data on product sales, customer demo...   \n",
       "2            retail  Extensive data on product sales, customer demo...   \n",
       "3            retail  Extensive data on product sales, customer demo...   \n",
       "4            retail  Extensive data on product sales, customer demo...   \n",
       "..              ...                                                ...   \n",
       "970  transportation  Extensive data on fleet management, logistics,...   \n",
       "971  transportation  Extensive data on fleet management, logistics,...   \n",
       "972  transportation  Extensive data on fleet management, logistics,...   \n",
       "973  transportation  Extensive data on fleet management, logistics,...   \n",
       "974  transportation  Extensive data on fleet management, logistics,...   \n",
       "\n",
       "       user_level                                     sql_complexity  \\\n",
       "0    intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
       "1    intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
       "2    intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
       "3    intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
       "4    intermediate  aggregation functions (COUNT, SUM, AVG, MIN, M...   \n",
       "..            ...                                                ...   \n",
       "970  intermediate  window functions (e.g., ROW_NUMBER, LEAD, LAG,...   \n",
       "971  intermediate  window functions (e.g., ROW_NUMBER, LEAD, LAG,...   \n",
       "972  intermediate  window functions (e.g., ROW_NUMBER, LEAD, LAG,...   \n",
       "973  intermediate  window functions (e.g., ROW_NUMBER, LEAD, LAG,...   \n",
       "974  intermediate  window functions (e.g., ROW_NUMBER, LEAD, LAG,...   \n",
       "\n",
       "                                              sql_task  \\\n",
       "0    data manipulation: inserting, updating, or del...   \n",
       "1    data manipulation: inserting, updating, or del...   \n",
       "2    data manipulation: inserting, updating, or del...   \n",
       "3    data manipulation: inserting, updating, or del...   \n",
       "4    data manipulation: inserting, updating, or del...   \n",
       "..                                                 ...   \n",
       "970  data manipulation: inserting, updating, or del...   \n",
       "971  data manipulation: inserting, updating, or del...   \n",
       "972  data manipulation: inserting, updating, or del...   \n",
       "973  data manipulation: inserting, updating, or del...   \n",
       "974  data manipulation: inserting, updating, or del...   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    Identify the top five cities in the United Sta...   \n",
       "1    What is the average price per square foot for ...   \n",
       "2    What are the top 5 cities in the United States...   \n",
       "3    Show me the average price per square foot for ...   \n",
       "4    Find all properties in California that have a ...   \n",
       "..                                                 ...   \n",
       "970  Add a new record to the Vehicles table for a N...   \n",
       "971  Update the customer's address in the Customers...   \n",
       "972  Delete the record from the Orders table where ...   \n",
       "973  Calculate the average mileage of all vehicles ...   \n",
       "974  Find the top 5 customers with the highest tota...   \n",
       "\n",
       "                                               context  \\\n",
       "0    CREATE TABLE listings (\\nlisting_id INT PRIMAR...   \n",
       "1    CREATE TABLE listings (\\nlisting_id INT PRIMAR...   \n",
       "2    CREATE TABLE US_Cities_Median_Home_Prices (Cit...   \n",
       "3    CREATE TABLE US_States_Avg_Price_Per_SqFt (Sta...   \n",
       "4    CREATE TABLE CA_Properties (Property_ID INT, A...   \n",
       "..                                                 ...   \n",
       "970  CREATE TABLE Vehicles (vehicle_id INT PRIMARY ...   \n",
       "971  CREATE TABLE Customers (customer_id INT PRIMAR...   \n",
       "972  CREATE TABLE Orders (order_id INT PRIMARY KEY,...   \n",
       "973  CREATE TABLE Vehicles (vehicle_id INT PRIMARY ...   \n",
       "974  CREATE TABLE Orders (order_id INT PRIMARY KEY,...   \n",
       "\n",
       "                                                   sql  \\\n",
       "0    SELECT city, state, median_price FROM median_p...   \n",
       "1    SELECT AVG(price / square_footage) AS average_...   \n",
       "2    SELECT City, State, Median_Home_Price FROM US_...   \n",
       "3    SELECT State, Avg_Price_Per_SqFt FROM US_State...   \n",
       "4    SELECT Address, List_Price, Bedrooms FROM CA_P...   \n",
       "..                                                 ...   \n",
       "970  INSERT INTO Vehicles (make, model, license_pla...   \n",
       "971  UPDATE Customers SET address = '123 Main St, A...   \n",
       "972           DELETE FROM Orders WHERE order_id = 789;   \n",
       "973  SELECT make, AVG(mileage) AS average_mileage F...   \n",
       "974  SELECT c.name, SUM(o.total_amount) AS total_or...   \n",
       "\n",
       "                                           explanation  \n",
       "0    This query first creates a view called `median...  \n",
       "1    This query calculates the average price per sq...  \n",
       "2    This SQL query selects the City, State, and Me...  \n",
       "3    This SQL query selects the State and Avg_Price...  \n",
       "4    This SQL query selects the Address, List_Price...  \n",
       "..                                                 ...  \n",
       "970  This SQL statement inserts a new row into the ...  \n",
       "971  This SQL statement updates the address of the ...  \n",
       "972  This SQL statement deletes the row from the Or...  \n",
       "973  This SQL statement calculates the average mile...  \n",
       "974  This SQL statement finds the top 5 customers w...  \n",
       "\n",
       "[975 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_text2sql_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4319747b-94ce-4a42-bcc2-4b430b35639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be69d632-5be7-42f9-a8c2-c0b2dee6859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import yaml\n",
    "from typing import Tuple\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, GenerationConfig\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "\n",
    "from llmtune.pydantic_models.config_model import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f1e997-66bf-441d-920f-0af7f454b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_HASH = \"eHP6Vw\"\n",
    "config_path = f\"./experiment/{EXPERIMENT_HASH}/config/config.yml\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    config = Config(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817f3da6-3d15-4526-8657-71d7cd1767a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac174992adc4e0ab74dfb8cc3e8441c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "weights_path = f\"./experiment/{EXPERIMENT_HASH}/weights/\"\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    weights_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "model = model.merge_and_unload()\n",
    "tok = AutoTokenizer.from_pretrained(weights_path, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0797ee20-b120-472a-be93-3c4e75973afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt: str, model, tok: AutoTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    Outputs predicted sequence and probability\n",
    "    \"\"\"\n",
    "    input_ids = tok.encode(prompt, return_tensors=\"pt\", truncation=True).cuda()\n",
    "    gen_config = GenerationConfig(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "        temperature=0.2,\n",
    "        pad_token_id=tok.pad_token_id,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        )\n",
    "\n",
    "    gen_results = model.generate(input_ids, gen_config)\n",
    "    gen_tok_ids = gen_results.sequences.squeeze(0)[input_ids.shape[1]:]\n",
    "\n",
    "    seq = tok.decode(gen_tok_ids, skip_special_tokens=True)\n",
    "\n",
    "    seq_score = torch.stack(gen_results.scores).squeeze(1) # get raw output scores \n",
    "    seq_score = torch.log(torch.softmax(seq_score, dim=1)) # softmax and log to get log_prob\n",
    "    seq_score = seq_score.gather(dim=1, index=gen_tok_ids.view(-1, 1)).squeeze()\n",
    "    seq_score = torch.exp(torch.sum(seq_score)).item() # sum and exp to get prob\n",
    "\n",
    "    return seq, seq_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48d32a-2eb9-4d32-8b7f-6ccb04790473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/500\n",
      "Done 2/500\n",
      "Done 3/500\n",
      "Done 4/500\n",
      "Done 5/500\n",
      "Done 6/500\n",
      "Done 7/500\n",
      "Done 8/500\n",
      "Done 9/500\n",
      "Done 10/500\n",
      "Done 11/500\n",
      "Done 12/500\n",
      "Done 13/500\n",
      "Done 14/500\n",
      "Done 15/500\n",
      "Done 16/500\n",
      "Done 17/500\n",
      "Done 18/500\n",
      "Done 19/500\n",
      "Done 20/500\n",
      "Done 21/500\n",
      "Done 22/500\n",
      "Done 23/500\n",
      "Done 24/500\n",
      "Done 25/500\n",
      "Done 26/500\n",
      "Done 27/500\n",
      "Done 28/500\n",
      "Done 29/500\n",
      "Done 30/500\n",
      "Done 31/500\n",
      "Done 32/500\n",
      "Done 33/500\n",
      "Done 34/500\n",
      "Done 35/500\n",
      "Done 36/500\n",
      "Done 37/500\n",
      "Done 38/500\n",
      "Done 39/500\n",
      "Done 40/500\n",
      "Done 41/500\n",
      "Done 42/500\n",
      "Done 43/500\n",
      "Done 44/500\n",
      "Done 45/500\n",
      "Done 46/500\n",
      "Done 47/500\n",
      "Done 48/500\n",
      "Done 49/500\n",
      "Done 50/500\n",
      "Done 51/500\n",
      "Done 52/500\n",
      "Done 53/500\n",
      "Done 54/500\n",
      "Done 55/500\n",
      "Done 56/500\n",
      "Done 57/500\n",
      "Done 58/500\n",
      "Done 59/500\n",
      "Done 60/500\n",
      "Done 61/500\n",
      "Done 62/500\n",
      "Done 63/500\n",
      "Done 64/500\n",
      "Done 65/500\n",
      "Done 66/500\n",
      "Done 67/500\n",
      "Done 68/500\n",
      "Done 69/500\n",
      "Done 70/500\n",
      "Done 71/500\n",
      "Done 72/500\n",
      "Done 73/500\n",
      "Done 74/500\n",
      "Done 75/500\n",
      "Done 76/500\n",
      "Done 77/500\n",
      "Done 78/500\n",
      "Done 79/500\n",
      "Done 80/500\n",
      "Done 81/500\n",
      "Done 82/500\n",
      "Done 83/500\n",
      "Done 84/500\n",
      "Done 85/500\n",
      "Done 86/500\n",
      "Done 87/500\n",
      "Done 88/500\n",
      "Done 89/500\n",
      "Done 90/500\n",
      "Done 91/500\n",
      "Done 92/500\n",
      "Done 93/500\n",
      "Done 94/500\n",
      "Done 95/500\n",
      "Done 96/500\n",
      "Done 97/500\n",
      "Done 98/500\n",
      "Done 99/500\n",
      "Done 100/500\n",
      "Done 101/500\n",
      "Done 102/500\n",
      "Done 103/500\n",
      "Done 104/500\n",
      "Done 105/500\n",
      "Done 106/500\n",
      "Done 107/500\n",
      "Done 108/500\n",
      "Done 109/500\n",
      "Done 110/500\n",
      "Done 111/500\n",
      "Done 112/500\n",
      "Done 113/500\n",
      "Done 114/500\n",
      "Done 115/500\n",
      "Done 116/500\n",
      "Done 117/500\n",
      "Done 118/500\n",
      "Done 119/500\n",
      "Done 120/500\n",
      "Done 121/500\n",
      "Done 122/500\n",
      "Done 123/500\n",
      "Done 124/500\n",
      "Done 125/500\n",
      "Done 126/500\n",
      "Done 127/500\n",
      "Done 128/500\n",
      "Done 129/500\n",
      "Done 130/500\n",
      "Done 131/500\n",
      "Done 132/500\n",
      "Done 133/500\n",
      "Done 134/500\n",
      "Done 135/500\n",
      "Done 136/500\n",
      "Done 137/500\n",
      "Done 138/500\n",
      "Done 139/500\n",
      "Done 140/500\n",
      "Done 141/500\n",
      "Done 142/500\n",
      "Done 143/500\n",
      "Done 144/500\n",
      "Done 145/500\n",
      "Done 146/500\n",
      "Done 147/500\n",
      "Done 148/500\n",
      "Done 149/500\n",
      "Done 150/500\n",
      "Done 151/500\n",
      "Done 152/500\n",
      "Done 153/500\n",
      "Done 154/500\n",
      "Done 155/500\n",
      "Done 156/500\n",
      "Done 157/500\n",
      "Done 158/500\n",
      "Done 159/500\n",
      "Done 160/500\n",
      "Done 161/500\n",
      "Done 162/500\n",
      "Done 163/500\n",
      "Done 164/500\n",
      "Done 165/500\n",
      "Done 166/500\n",
      "Done 167/500\n",
      "Done 168/500\n",
      "Done 169/500\n",
      "Done 170/500\n",
      "Done 171/500\n",
      "Done 172/500\n",
      "Done 173/500\n",
      "Done 174/500\n",
      "Done 175/500\n",
      "Done 176/500\n",
      "Done 177/500\n",
      "Done 178/500\n",
      "Done 179/500\n",
      "Done 180/500\n",
      "Done 181/500\n",
      "Done 182/500\n",
      "Done 183/500\n",
      "Done 184/500\n",
      "Done 185/500\n",
      "Done 186/500\n",
      "Done 187/500\n",
      "Done 188/500\n",
      "Done 189/500\n",
      "Done 190/500\n",
      "Done 191/500\n",
      "Done 192/500\n",
      "Done 193/500\n",
      "Done 194/500\n",
      "Done 195/500\n",
      "Done 196/500\n",
      "Done 197/500\n",
      "Done 198/500\n",
      "Done 199/500\n",
      "Done 200/500\n",
      "Done 201/500\n",
      "Done 202/500\n",
      "Done 203/500\n",
      "Done 204/500\n",
      "Done 205/500\n",
      "Done 206/500\n",
      "Done 207/500\n",
      "Done 208/500\n",
      "Done 209/500\n",
      "Done 210/500\n",
      "Done 211/500\n",
      "Done 212/500\n",
      "Done 213/500\n",
      "Done 214/500\n",
      "Done 215/500\n",
      "Done 216/500\n",
      "Done 217/500\n",
      "Done 218/500\n",
      "Done 219/500\n",
      "Done 220/500\n",
      "Done 221/500\n",
      "Done 222/500\n",
      "Done 223/500\n",
      "Done 224/500\n",
      "Done 225/500\n",
      "Done 226/500\n",
      "Done 227/500\n",
      "Done 228/500\n",
      "Done 229/500\n",
      "Done 230/500\n",
      "Done 231/500\n",
      "Done 232/500\n",
      "Done 233/500\n",
      "Done 234/500\n",
      "Done 235/500\n",
      "Done 236/500\n",
      "Done 237/500\n",
      "Done 238/500\n",
      "Done 239/500\n",
      "Done 240/500\n",
      "Done 241/500\n",
      "Done 242/500\n",
      "Done 243/500\n",
      "Done 244/500\n",
      "Done 245/500\n",
      "Done 246/500\n",
      "Done 247/500\n",
      "Done 248/500\n",
      "Done 249/500\n",
      "Done 250/500\n",
      "Done 251/500\n",
      "Done 252/500\n",
      "Done 253/500\n",
      "Done 254/500\n",
      "Done 255/500\n",
      "Done 256/500\n",
      "Done 257/500\n",
      "Done 258/500\n",
      "Done 259/500\n",
      "Done 260/500\n",
      "Done 261/500\n",
      "Done 262/500\n",
      "Done 263/500\n",
      "Done 264/500\n",
      "Done 265/500\n",
      "Done 266/500\n",
      "Done 267/500\n",
      "Done 268/500\n",
      "Done 269/500\n",
      "Done 270/500\n",
      "Done 271/500\n",
      "Done 272/500\n",
      "Done 273/500\n",
      "Done 274/500\n",
      "Done 275/500\n",
      "Done 276/500\n",
      "Done 277/500\n",
      "Done 278/500\n",
      "Done 279/500\n",
      "Done 280/500\n",
      "Done 281/500\n",
      "Done 282/500\n",
      "Done 283/500\n",
      "Done 284/500\n",
      "Done 285/500\n",
      "Done 286/500\n",
      "Done 287/500\n",
      "Done 288/500\n",
      "Done 289/500\n",
      "Done 290/500\n",
      "Done 291/500\n",
      "Done 292/500\n",
      "Done 293/500\n",
      "Done 294/500\n",
      "Done 295/500\n",
      "Done 296/500\n",
      "Done 297/500\n",
      "Done 298/500\n",
      "Done 299/500\n",
      "Done 300/500\n",
      "Done 301/500\n",
      "Done 302/500\n",
      "Done 303/500\n",
      "Done 304/500\n",
      "Done 305/500\n",
      "Done 306/500\n",
      "Done 307/500\n",
      "Done 308/500\n",
      "Done 309/500\n",
      "Done 310/500\n",
      "Done 311/500\n",
      "Done 312/500\n",
      "Done 313/500\n",
      "Done 314/500\n",
      "Done 315/500\n",
      "Done 316/500\n",
      "Done 317/500\n",
      "Done 318/500\n",
      "Done 319/500\n",
      "Done 320/500\n",
      "Done 321/500\n",
      "Done 322/500\n",
      "Done 323/500\n",
      "Done 324/500\n",
      "Done 325/500\n",
      "Done 326/500\n",
      "Done 327/500\n",
      "Done 328/500\n",
      "Done 329/500\n",
      "Done 330/500\n",
      "Done 331/500\n",
      "Done 332/500\n",
      "Done 333/500\n",
      "Done 334/500\n",
      "Done 335/500\n",
      "Done 336/500\n",
      "Done 337/500\n",
      "Done 338/500\n",
      "Done 339/500\n",
      "Done 340/500\n",
      "Done 341/500\n",
      "Done 342/500\n",
      "Done 343/500\n",
      "Done 344/500\n",
      "Done 345/500\n",
      "Done 346/500\n",
      "Done 347/500\n",
      "Done 348/500\n",
      "Done 349/500\n",
      "Done 350/500\n",
      "Done 351/500\n",
      "Done 352/500\n",
      "Done 353/500\n",
      "Done 354/500\n",
      "Done 355/500\n",
      "Done 356/500\n",
      "Done 357/500\n",
      "Done 358/500\n",
      "Done 359/500\n",
      "Done 360/500\n",
      "Done 361/500\n",
      "Done 362/500\n",
      "Done 363/500\n",
      "Done 364/500\n",
      "Done 365/500\n",
      "Done 366/500\n",
      "Done 367/500\n",
      "Done 368/500\n",
      "Done 369/500\n",
      "Done 370/500\n",
      "Done 371/500\n",
      "Done 372/500\n",
      "Done 373/500\n",
      "Done 374/500\n",
      "Done 375/500\n",
      "Done 376/500\n",
      "Done 377/500\n",
      "Done 378/500\n",
      "Done 379/500\n",
      "Done 380/500\n",
      "Done 381/500\n",
      "Done 382/500\n",
      "Done 383/500\n",
      "Done 384/500\n",
      "Done 385/500\n",
      "Done 386/500\n",
      "Done 387/500\n",
      "Done 388/500\n",
      "Done 389/500\n",
      "Done 390/500\n",
      "Done 391/500\n",
      "Done 392/500\n",
      "Done 393/500\n",
      "Done 394/500\n",
      "Done 395/500\n",
      "Done 396/500\n",
      "Done 397/500\n",
      "Done 398/500\n",
      "Done 399/500\n",
      "Done 400/500\n",
      "Done 401/500\n",
      "Done 402/500\n",
      "Done 403/500\n",
      "Done 404/500\n",
      "Done 405/500\n",
      "Done 406/500\n",
      "Done 407/500\n",
      "Done 408/500\n",
      "Done 409/500\n",
      "Done 410/500\n",
      "Done 411/500\n",
      "Done 412/500\n",
      "Done 413/500\n",
      "Done 414/500\n",
      "Done 415/500\n",
      "Done 416/500\n",
      "Done 417/500\n",
      "Done 418/500\n",
      "Done 419/500\n",
      "Done 420/500\n",
      "Done 421/500\n",
      "Done 422/500\n",
      "Done 423/500\n",
      "Done 424/500\n",
      "Done 425/500\n",
      "Done 426/500\n",
      "Done 427/500\n",
      "Done 428/500\n",
      "Done 429/500\n",
      "Done 430/500\n",
      "Done 431/500\n",
      "Done 432/500\n",
      "Done 433/500\n",
      "Done 434/500\n",
      "Done 435/500\n",
      "Done 436/500\n",
      "Done 437/500\n",
      "Done 438/500\n",
      "Done 439/500\n",
      "Done 440/500\n",
      "Done 441/500\n",
      "Done 442/500\n",
      "Done 443/500\n",
      "Done 444/500\n",
      "Done 445/500\n",
      "Done 446/500\n",
      "Done 447/500\n",
      "Done 448/500\n",
      "Done 449/500\n",
      "Done 450/500\n",
      "Done 451/500\n",
      "Done 452/500\n",
      "Done 453/500\n",
      "Done 454/500\n",
      "Done 455/500\n",
      "Done 456/500\n",
      "Done 457/500\n",
      "Done 458/500\n",
      "Done 459/500\n",
      "Done 460/500\n",
      "Done 461/500\n",
      "Done 462/500\n",
      "Done 463/500\n",
      "Done 464/500\n",
      "Done 465/500\n",
      "Done 466/500\n",
      "Done 467/500\n",
      "Done 468/500\n",
      "Done 469/500\n",
      "Done 470/500\n",
      "Done 471/500\n",
      "Done 472/500\n",
      "Done 473/500\n",
      "Done 474/500\n",
      "Done 475/500\n",
      "Done 476/500\n",
      "Done 477/500\n",
      "Done 478/500\n",
      "Done 479/500\n",
      "Done 480/500\n",
      "Done 481/500\n",
      "Done 482/500\n",
      "Done 483/500\n",
      "Done 484/500\n",
      "Done 485/500\n",
      "Done 486/500\n"
     ]
    }
   ],
   "source": [
    "with open(\"prompts.csv\", mode='r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = next(reader)  # Read the header\n",
    "    data = [tuple(row) for row in reader]  # Read the data and convert each row to a tuple\n",
    "\n",
    "processed_preds = {}\n",
    "for idx, row in enumerate(data):\n",
    "    out, _ = infer(row[1], model, tok)\n",
    "    out = out.strip()\n",
    "    out += f\"\\t----- bird -----\\t{data[idx][0]}\"\n",
    "    processed_preds[str(idx)] = out\n",
    "    print(f\"Done {idx+1}/{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ba15b-7c7a-47b1-ac71-0cd72e0df558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ca7077-44b3-4647-8aeb-6aaadf4c7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"predict_mini_dev_mistral-navigator_SQLite.json\", 'w') as json_file:\n",
    "    json.dump(processed_preds, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc290a-8077-4ff1-938a-4686b4849a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
